# ollama-chat
JavaScript chatbot UI for LLMs running locally with Ollama

Vibe coded with Gemini

## Features
  - Chat with any LLM running locally on Ollama
  - Automatically discovers available LLMs locally installed with Ollama
  - Chat history stored in browser's local storage
  - Drag and drop files to attach them to the prompt

## Quickstart
Assumes that you already have Ollama installed and running with at least one LLM downloaded.

Run with any local web server (e.g. `python3 -m http.server`)

